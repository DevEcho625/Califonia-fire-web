{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbc2937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wildfire_risk_notebook.py\n",
    "# Notebook-style script: paste into a Jupyter cell or run as a .py (line-by-line)\n",
    "\n",
    "# --- 0. Install / import (uncomment if using in a clean env) ---\n",
    "# !pip install geopandas shapely rtree fiona pyproj scikit-learn matplotlib tqdm requests\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, box\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.exc import GeocoderTimedOut, GeocoderServiceError\n",
    "\n",
    "# --- 1. Paths & data sources ---\n",
    "WFIGS_CSV = r\"C:\\Users\\anujx\\Downloads\\WFIGS_Incident_Locations_-835549102613066266 (2).csv\"\n",
    "\n",
    "CALFIRE_GEOJSON_URLS = [\n",
    "    \"https://data.ca.gov/dataset/california-fire-perimeters-all/resource/dd5e4337-8679-4d64-bd90-b9df85ee6b58/download\", \n",
    "    \"https://services.arcgis.com/jIL9msH9OI208GCb/ArcGIS/rest/services/California_Fire_Perimeters_1878_2019/FeatureServer/1/query?where=1%3D1&outFields=*&f=geojson\",\n",
    "    \"https://gis.data.cnra.ca.gov/arcgis/rest/services/CALFIRE-Forestry/california-fire-perimeters-all/FeatureServer/0/query?where=1%3D1&outFields=*&f=geojson\"\n",
    "]\n",
    "\n",
    "def load_calfire_geojson_try(urls=CALFIRE_GEOJSON_URLS):\n",
    "    \"\"\"Try multiple sources until CAL FIRE GeoJSON loads.\"\"\"\n",
    "    for url in urls:\n",
    "        try:\n",
    "            print(\"Trying:\", url)\n",
    "            r = requests.get(url, timeout=60)\n",
    "            r.raise_for_status()\n",
    "            ct = r.headers.get(\"Content-Type\", \"\")\n",
    "            if \"json\" in ct or \"geojson\" in ct or r.text.strip().startswith(\"{\"):\n",
    "                data = r.json()\n",
    "                gdf = gpd.GeoDataFrame.from_features(data[\"features\"], crs=\"EPSG:4326\")\n",
    "                print(\"Loaded GeoJSON from:\", url)\n",
    "                return gdf\n",
    "            else:\n",
    "                print(\"Response not GeoJSON ({}): trying geopandas read_file fallback\".format(ct))\n",
    "                try:\n",
    "                    gdf = gpd.read_file(url)\n",
    "                    return gdf\n",
    "                except Exception as e:\n",
    "                    print(\"geopandas read_file failed for\", url, \"error:\", e)\n",
    "        except Exception as e:\n",
    "            print(\"Failed to load from\", url, \":\", e)\n",
    "    raise RuntimeError(\"Could not automatically download CAL FIRE perimeters.\")\n",
    "\n",
    "def is_in_california_geopy(latitude, longitude):\n",
    "    \"\"\"\n",
    "    Checks if a given latitude and longitude pair is within California using geopy.\n",
    "    \"\"\"\n",
    "    geolocator = Nominatim(user_agent=\"my-geocoding-app\") # Replace with your app name\n",
    "    try:\n",
    "        location = geolocator.reverse(f\"{latitude},{longitude}\", exactly_one=True)\n",
    "        if location and \"state\" in location.raw[\"address\"]:\n",
    "            return location.raw[\"address\"][\"state\"] == \"California\"\n",
    "        return False\n",
    "    except (GeocoderTimedOut, GeocoderServiceError) as e:\n",
    "        print(f\"Geocoding error: {e}\")\n",
    "        return False\n",
    "\n",
    "# --- 2. Load WFIGS incidents CSV ---\n",
    "print(\"Loading WFIGS incidents CSV...\")\n",
    "wf_df = pd.read_csv(WFIGS_CSV, low_memory=False)\n",
    "print(\"Columns in WFIGS CSV:\", wf_df.columns.tolist())\n",
    "\n",
    "# Detect coordinate columns\n",
    "lat_col, lon_col = None, None\n",
    "for c in [\"Latitude\", \"LAT\", \"lat\", \"Y\", \"POINT_Y\", \"InitialLatitude\"]:\n",
    "    if c in wf_df.columns:\n",
    "        lat_col = c\n",
    "        break\n",
    "for c in [\"Longitude\", \"LON\", \"lon\", \"X\", \"POINT_X\", \"InitialLongitude\"]:\n",
    "    if c in wf_df.columns:\n",
    "        lon_col = c\n",
    "        break\n",
    "\n",
    "if not lat_col or not lon_col:\n",
    "    raise RuntimeError(\"No latitude/longitude columns found.\")\n",
    "\n",
    "# Drop missing coords and convert to GeoDataFrame\n",
    "# Drop missing coords\n",
    "wf_df = wf_df.dropna(subset=[lat_col, lon_col]).copy()\n",
    "\n",
    "# Filter to California\n",
    "mask = [is_in_california_geopy(lat, lon) for lat, lon in zip(wf_df[lat_col], wf_df[lon_col])]\n",
    "wf_df = wf_df[mask].copy()\n",
    "print(f\"WFIGS points after California filter: {len(wf_df)}\")\n",
    "\n",
    "# Convert to GeoDataFrame (keep this)\n",
    "wf_gdf = gpd.GeoDataFrame(\n",
    "    wf_df,\n",
    "    geometry=[Point(xy) for xy in zip(wf_df[lon_col], wf_df[lat_col])],\n",
    "    crs=\"EPSG:4326\"\n",
    ")\n",
    "\n",
    "\n",
    "# Remove invalid geometries\n",
    "wf_gdf = wf_gdf[wf_gdf.geometry.notnull() & ~wf_gdf.geometry.is_empty]\n",
    "if wf_gdf.empty:\n",
    "    raise RuntimeError(\"No valid WFIGS points after cleaning.\")\n",
    "\n",
    "# Reproject to California Albers (meters)\n",
    "wf_gdf = wf_gdf.to_crs(\"EPSG:3310\")\n",
    "print(\"Loaded WFIGS points:\", len(wf_gdf))\n",
    "print(\"Reprojected WFIGS CRS:\", wf_gdf.crs)\n",
    "\n",
    "\n",
    "# --- 3. Load CAL FIRE perimeters ---\n",
    "print(\"Downloading/reading CAL FIRE perimeters (FRAP)...\")\n",
    "calfire_url = CALFIRE_GEOJSON_URLS[1]  # you can cycle URLs if needed\n",
    "calfire_gdf = gpd.read_file(calfire_url)\n",
    "\n",
    "# Clean invalid geometries\n",
    "calfire_gdf = calfire_gdf[~calfire_gdf.geometry.is_empty]\n",
    "calfire_gdf = calfire_gdf[calfire_gdf.geometry.notnull()]\n",
    "calfire_gdf[\"geometry\"] = calfire_gdf[\"geometry\"].buffer(0)\n",
    "calfire_gdf = calfire_gdf[calfire_gdf.is_valid]\n",
    "\n",
    "# Reproject to California Albers\n",
    "calfire_gdf = calfire_gdf.to_crs(\"EPSG:3310\")\n",
    "print(\"CAL FIRE perimeters loaded. Features:\", len(calfire_gdf))\n",
    "print(\"CALFIRE bounds:\", calfire_gdf.total_bounds)\n",
    "\n",
    "# --- 4. Generate grid for modeling ---\n",
    "# Approximate California bounds in EPSG:3310 (meters)\n",
    "cell_size = 1000  # 1 km grid cells\n",
    "ca_minx, ca_miny = -2500000, -2500000\n",
    "ca_maxx, ca_maxy = 1100000, 1300000\n",
    "\n",
    "# Clip WFIGS points to California bounds\n",
    "wf_gdf = wf_gdf.cx[ca_minx:ca_maxx, ca_miny:ca_maxy]\n",
    "if wf_gdf.empty:\n",
    "    raise RuntimeError(\"No WFIGS points within California bounds.\")\n",
    "\n",
    "# Compute grid bounds safely\n",
    "minx, miny, maxx, maxy = wf_gdf.total_bounds\n",
    "nx = int(np.ceil((maxx - minx) / cell_size))\n",
    "ny = int(np.ceil((maxy - miny) / cell_size))\n",
    "\n",
    "print(f\"Grid size: {nx} Ã— {ny}\")\n",
    "\n",
    "grid_polys, grid_centroids = [], []\n",
    "for i in range(nx):\n",
    "    for j in range(ny):\n",
    "        x0, y0 = minx + i*cell_size, miny + j*cell_size\n",
    "        x1, y1 = x0 + cell_size, y0 + cell_size\n",
    "        grid_polys.append(box(x0, y0, x1, y1))\n",
    "        grid_centroids.append(((x0+x1)/2, (y0+y1)/2))\n",
    "\n",
    "grid_gdf = gpd.GeoDataFrame(geometry=grid_polys, crs=\"EPSG:3310\")\n",
    "grid_gdf[\"centroid\"] = [Point(c) for c in grid_centroids]\n",
    "\n",
    "# Clip grid to area around WFIGS points (study area)\n",
    "study_buffer = 5000\n",
    "study_box = box(wf_bounds[0]-study_buffer, wf_bounds[1]-study_buffer,\n",
    "                wf_bounds[2]+study_buffer, wf_bounds[3]+study_buffer)\n",
    "grid_gdf = grid_gdf[grid_gdf.intersects(study_box)].reset_index(drop=True)\n",
    "print(\"Grid cells after clipping:\", len(grid_gdf))\n",
    "\n",
    "# --- 5. Compute features ---\n",
    "calfire_gdf[\"perim_area\"] = calfire_gdf.geometry.area\n",
    "calfire_sindex = calfire_gdf.sindex\n",
    "\n",
    "def compute_burned_area_for_cell(cell_geom):\n",
    "    possible_idx = list(calfire_sindex.intersection(cell_geom.bounds))\n",
    "    return sum(\n",
    "        calfire_gdf.geometry.iloc[i].intersection(cell_geom).area\n",
    "        for i in possible_idx\n",
    "        if calfire_gdf.geometry.iloc[i].intersects(cell_geom)\n",
    "    )\n",
    "\n",
    "grid_gdf[\"burned_area_m2\"] = [\n",
    "    compute_burned_area_for_cell(g) for g in tqdm(grid_gdf.geometry, desc=\"computing burned area\")\n",
    "]\n",
    "grid_gdf[\"burned_area_km2\"] = grid_gdf[\"burned_area_m2\"] / 1e6\n",
    "\n",
    "def count_perimeters_in_cell(cell_geom):\n",
    "    possible_idx = list(calfire_sindex.intersection(cell_geom.bounds))\n",
    "    return sum(\n",
    "        calfire_gdf.geometry.iloc[i].intersects(cell_geom)\n",
    "        for i in possible_idx\n",
    "    )\n",
    "\n",
    "grid_gdf[\"burn_count\"] = [\n",
    "    count_perimeters_in_cell(g) for g in tqdm(grid_gdf.geometry, desc=\"counting perimeters\")\n",
    "]\n",
    "\n",
    "# Distance to nearest perimeter\n",
    "centroids = gpd.GeoSeries([p for p in grid_gdf.centroid], crs=\"EPSG:3310\")\n",
    "nearest_distances = []\n",
    "for c in tqdm(centroids, desc=\"computing distance\"):\n",
    "    try:\n",
    "        possible_idx = list(calfire_sindex.nearest(c.bounds))\n",
    "    except TypeError:\n",
    "        possible_idx = list(calfire_sindex.intersection(c.bounds))\n",
    "    dmin = np.min([c.distance(calfire_gdf.geometry.iloc[i]) for i in possible_idx]) if possible_idx else np.inf\n",
    "    nearest_distances.append(dmin if np.isfinite(dmin) else 0)\n",
    "\n",
    "grid_gdf[\"dist_to_perimeter_m\"] = nearest_distances\n",
    "\n",
    "# --- 6. Label fire occurrence ---\n",
    "wf_sindex = wf_gdf.sindex\n",
    "labels = []\n",
    "for geom in tqdm(grid_gdf.geometry, desc=\"labeling cells\"):\n",
    "    possible = list(wf_sindex.intersection(geom.bounds))\n",
    "    labels.append(\n",
    "        any(wf_gdf.geometry.iloc[i].within(geom) for i in possible)\n",
    "    )\n",
    "grid_gdf[\"label_fire\"] = np.array(labels, dtype=int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d474225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 6. Model or heuristic scoring ---\n",
    "feature_cols = [\"burned_area_km2\", \"burn_count\", \"dist_to_perimeter_m\"]\n",
    "X = grid_gdf[feature_cols].fillna(0).values\n",
    "\n",
    "# --- Safety check: Ensure grid_gdf is not empty ---\n",
    "if len(grid_gdf) == 0:\n",
    "    raise ValueError(\"Grid generation failed â€” no cells created. Check bounding box or CRS mismatch.\")\n",
    "\n",
    "print(grid_gdf)\n",
    "print(grid_gdf.keys())\n",
    "print(X)\n",
    "y = grid_gdf[\"label_fire\"].values\n",
    "\n",
    "# Invert distance to represent proximity\n",
    "X[:, 2] = 1.0 / (1.0 + (X[:, 2] / 1000.0))\n",
    "\n",
    "scaler = StandardScaler()\n",
    "print(scaler)\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "if y.sum() == 0:\n",
    "    print(\"No labeled fires found â€” using heuristic risk score.\")\n",
    "    wa, wb, wc = 0.5, 0.3, 0.2\n",
    "    raw = wa*X[:,0]/(X[:,0].max()+1e-9) + wb*X[:,1]/(X[:,1].max()+1e-9) + wc*X[:,2]/(X[:,2].max()+1e-9)\n",
    "    risk = (raw - raw.min()) / (raw.max() - raw.min() + 1e-9)\n",
    "    grid_gdf[\"fire_likelihood\"] = risk\n",
    "else:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.25, stratify=y, random_state=42)\n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "    proba = model.predict_proba(X_scaled)[:,1]\n",
    "    auc = roc_auc_score(y_test, model.predict_proba(X_test)[:,1])\n",
    "    print(\"Model ROC AUC:\", auc)\n",
    "    grid_gdf[\"fire_likelihood\"] = proba\n",
    "\"\"\"\n",
    "# --- 7. Output and visualize ---\n",
    "out_geojson = \"grid_fire_likelihood.geojson\"\n",
    "out_csv = \"grid_fire_likelihood.csv\"\n",
    "grid_gdf.to_file(out_geojson, driver=\"GeoJSON\")\n",
    "\n",
    "grid_out = grid_gdf.copy()\n",
    "grid_out[\"centroid_x\"] = [p.x for p in grid_out.centroid]\n",
    "grid_out[\"centroid_y\"] = [p.y for p in grid_out.centroid]\n",
    "grid_out[[\"centroid_x\", \"centroid_y\", \"burned_area_km2\", \"burn_count\", \"dist_to_perimeter_m\", \"fire_likelihood\"]].to_csv(out_csv, index=False)\n",
    "print(\"Saved:\", out_csv, out_geojson)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "calfire_gdf.plot(ax=ax, linewidth=0.2, edgecolor=\"gray\")\n",
    "grid_gdf.plot(column=\"fire_likelihood\", ax=ax, alpha=0.8, legend=True)\n",
    "wf_gdf.plot(ax=ax, markersize=5, color=\"black\")\n",
    "plt.title(\"Predicted Fire Likelihood (0â€“1)\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Risk stats: min {:.3f}, mean {:.3f}, max {:.3f}\".format(\n",
    "    grid_gdf[\"fire_likelihood\"].min(),\n",
    "    grid_gdf[\"fire_likelihood\"].mean(),\n",
    "    grid_gdf[\"fire_likelihood\"].max()\n",
    "))\n",
    "\n",
    "*/\n",
    "\"\"\"\n",
    "# --- 7. Output and visualize ---\n",
    "out_geojson = \"grid_fire_likelihood.geojson\"\n",
    "out_csv = \"grid_fire_likelihood.csv\"\n",
    "grid_gdf.to_file(out_geojson, driver=\"GeoJSON\")\n",
    "\n",
    "grid_out = grid_gdf.copy()\n",
    "grid_out[\"centroid_x\"] = [p.x for p in grid_out.centroid]\n",
    "grid_out[\"centroid_y\"] = [p.y for p in grid_out.centroid]\n",
    "grid_out[[\"centroid_x\", \"centroid_y\", \"burned_area_km2\", \"burn_count\", \"dist_to_perimeter_m\", \"fire_likelihood\"]].to_csv(out_csv, index=False)\n",
    "print(\"Saved:\", out_csv, out_geojson)\n",
    "\n",
    "# âœ… FIX: ensure coordinate systems match\n",
    "wf_gdf = wf_gdf.to_crs(grid_gdf.crs)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "calfire_gdf.plot(ax=ax, linewidth=0.2, edgecolor=\"gray\")\n",
    "grid_gdf.plot(column=\"fire_likelihood\", ax=ax, alpha=0.8, legend=True)\n",
    "wf_gdf.plot(ax=ax, markersize=5, color=\"black\")\n",
    "plt.title(\"Predicted Fire Likelihood (0â€“1)\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Risk stats: min {:.3f}, mean {:.3f}, max {:.3f}\".format(\n",
    "    grid_gdf[\"fire_likelihood\"].min(),\n",
    "    grid_gdf[\"fire_likelihood\"].mean(),\n",
    "    grid_gdf[\"fire_likelihood\"].max()\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "316f19a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading WFIGS incidents CSV...\n",
      "Columns in WFIGS CSV: ['OBJECTID', 'SourceOID', 'ABCDMisc', 'ADSPermissionState', 'ContainmentDateTime', 'ControlDateTime', 'CreatedBySystem', 'IncidentSize', 'DiscoveryAcres', 'DispatchCenterID', 'EstimatedCostToDate', 'FinalAcres', 'FinalFireReportApprovedByTitle', 'FinalFireReportApprovedByUnit', 'FinalFireReportApprovedDate', 'FireBehaviorGeneral', 'FireBehaviorGeneral1', 'FireBehaviorGeneral2', 'FireBehaviorGeneral3', 'FireCause', 'FireCauseGeneral', 'FireCauseSpecific', 'FireCode', 'FireDepartmentID', 'FireDiscoveryDateTime', 'FireMgmtComplexity', 'FireOutDateTime', 'FireStrategyConfinePercent', 'FireStrategyFullSuppPercent', 'FireStrategyMonitorPercent', 'FireStrategyPointZonePercent', 'FSJobCode', 'FSOverrideCode', 'GACC', 'ICS209ReportDateTime', 'ICS209ReportForTimePeriodFrom', 'ICS209ReportForTimePeriodTo', 'ICS209ReportStatus', 'IncidentManagementOrganization', 'IncidentName', 'IncidentShortDescription', 'IncidentTypeCategory', 'IncidentTypeKind', 'InitialLatitude', 'InitialLongitude', 'InitialResponseAcres', 'InitialResponseDateTime', 'IrwinID', 'IsFireCauseInvestigated', 'IsFireCodeRequested', 'IsFSAssisted', 'IsMultiJurisdictional', 'IsQuarantined', 'IsReimbursable', 'IsTrespass', 'IsUnifiedCommand', 'IsValid', 'LocalIncidentIdentifier', 'PercentContained', 'PercentPerimeterToBeContained', 'POOCity', 'POOCounty', 'POODispatchCenterID', 'POOFips', 'POOJurisdictionalAgency', 'POOJurisdictionalUnit', 'POOJurisdictionalUnitParentUnit', 'POOLandownerCategory', 'POOLandownerKind', 'POOLegalDescPrincipalMeridian', 'POOLegalDescQtr', 'POOLegalDescQtrQtr', 'POOLegalDescRange', 'POOLegalDescSection', 'POOLegalDescTownship', 'POOPredictiveServiceAreaID', 'POOProtectingAgency', 'POOProtectingUnit', 'POOState', 'PredominantFuelGroup', 'PredominantFuelModel', 'PrimaryFuelModel', 'SecondaryFuelModel', 'TotalIncidentPersonnel', 'UniqueFireIdentifier', 'WFDSSDecisionStatus', 'EstimatedFinalCost', 'OrganizationalAssessment', 'StrategicDecisionPublishDate', 'CreatedOnDateTime_dt', 'ModifiedOnDateTime_dt', 'IsCpxChild', 'CpxName', 'CpxID', 'SourceGlobalID', 'GlobalID', 'IncidentComplexityLevel', 'x', 'y']\n",
      "Original WFIGS points: 379582\n",
      "WFIGS points after dropping missing coordinates: 294787\n",
      "Coordinate range - InitialLatitude: -1764.78333333 to 3549.602\n",
      "Coordinate range - InitialLongitude: -10149.76666666 to 190.85\n",
      "Coordinates appear to be scaled lat/lon, trying different scales...\n",
      "  Scale 1000: lat 0.028 to 0.068, lon -0.149 to -0.081\n",
      "  Scale 10000: lat 0.003 to 0.007, lon -0.015 to -0.008\n",
      "  Scale 100000: lat 0.000 to 0.001, lon -0.001 to -0.001\n",
      "  Scale 1000000: lat 0.000 to 0.000, lon -0.000 to -0.000\n",
      "  [X] No scale factor produced reasonable US coordinates\n",
      "Converted coordinate range - lat: -1764.783333 to 3549.602000\n",
      "Converted coordinate range - lon: -10149.766667 to 190.850000\n",
      "Pre-filtering using California bounding box...\n",
      "California bounding box: 32.43Â°N to 42.0Â°N, -124.42Â°W to -114.12Â°W\n",
      "Points within California bounding box: 96609 out of 294787\n",
      "Loading California boundary for precise filtering...\n"
     ]
    },
    {
     "ename": "DataSourceError",
     "evalue": "California_County_Boundary_view_layer_for_public_use_-4560719754002809188.geojson: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mDataSourceError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 260\u001b[39m\n\u001b[32m    257\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    258\u001b[39m     \u001b[38;5;66;03m# Now apply precise GeoJSON boundary filter to the pre-filtered points\u001b[39;00m\n\u001b[32m    259\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mLoading California boundary for precise filtering...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m260\u001b[39m     california_gdf = \u001b[43mgpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_file\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mCalifornia_County_Boundary_view_layer_for_public_use_-4560719754002809188.geojson\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    261\u001b[39m     california_gdf = california_gdf.dissolve()  \u001b[38;5;66;03m# Combine all counties into single boundary\u001b[39;00m\n\u001b[32m    263\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mApplying precise California boundary filter...\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\anujx\\Documents\\GitHub\\venv\\Lib\\site-packages\\geopandas\\io\\file.py:316\u001b[39m, in \u001b[36m_read_file\u001b[39m\u001b[34m(filename, bbox, mask, columns, rows, engine, **kwargs)\u001b[39m\n\u001b[32m    313\u001b[39m             filename = response.read()\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m engine == \u001b[33m\"\u001b[39m\u001b[33mpyogrio\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read_file_pyogrio\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    317\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbbox\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbbox\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrows\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    318\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    320\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m engine == \u001b[33m\"\u001b[39m\u001b[33mfiona\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    321\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m pd.api.types.is_file_like(filename):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\anujx\\Documents\\GitHub\\venv\\Lib\\site-packages\\geopandas\\io\\file.py:576\u001b[39m, in \u001b[36m_read_file_pyogrio\u001b[39m\u001b[34m(path_or_bytes, bbox, mask, rows, **kwargs)\u001b[39m\n\u001b[32m    567\u001b[39m     warnings.warn(\n\u001b[32m    568\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe \u001b[39m\u001b[33m'\u001b[39m\u001b[33minclude_fields\u001b[39m\u001b[33m'\u001b[39m\u001b[33m and \u001b[39m\u001b[33m'\u001b[39m\u001b[33mignore_fields\u001b[39m\u001b[33m'\u001b[39m\u001b[33m keywords are deprecated, and \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    569\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mwill be removed in a future release. You can use the \u001b[39m\u001b[33m'\u001b[39m\u001b[33mcolumns\u001b[39m\u001b[33m'\u001b[39m\u001b[33m keyword \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    572\u001b[39m         stacklevel=\u001b[32m3\u001b[39m,\n\u001b[32m    573\u001b[39m     )\n\u001b[32m    574\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mcolumns\u001b[39m\u001b[33m\"\u001b[39m] = kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33minclude_fields\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m576\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpyogrio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_bytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbbox\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbbox\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\anujx\\Documents\\GitHub\\venv\\Lib\\site-packages\\pyogrio\\geopandas.py:275\u001b[39m, in \u001b[36mread_dataframe\u001b[39m\u001b[34m(path_or_buffer, layer, encoding, columns, read_geometry, force_2d, skip_features, max_features, where, bbox, mask, fids, sql, sql_dialect, fid_as_index, use_arrow, on_invalid, arrow_to_pandas_kwargs, **kwargs)\u001b[39m\n\u001b[32m    270\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m use_arrow:\n\u001b[32m    271\u001b[39m     \u001b[38;5;66;03m# For arrow, datetimes are read as is.\u001b[39;00m\n\u001b[32m    272\u001b[39m     \u001b[38;5;66;03m# For numpy IO, datetimes are read as string values to preserve timezone info\u001b[39;00m\n\u001b[32m    273\u001b[39m     \u001b[38;5;66;03m# as numpy does not directly support timezones.\u001b[39;00m\n\u001b[32m    274\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mdatetime_as_string\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m275\u001b[39m result = \u001b[43mread_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    276\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    277\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    278\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    279\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    280\u001b[39m \u001b[43m    \u001b[49m\u001b[43mread_geometry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mread_geometry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    281\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforce_2d\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgdal_force_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    282\u001b[39m \u001b[43m    \u001b[49m\u001b[43mskip_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskip_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    283\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    284\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    285\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbbox\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbbox\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    286\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    287\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    288\u001b[39m \u001b[43m    \u001b[49m\u001b[43msql\u001b[49m\u001b[43m=\u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    289\u001b[39m \u001b[43m    \u001b[49m\u001b[43msql_dialect\u001b[49m\u001b[43m=\u001b[49m\u001b[43msql_dialect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    290\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_fids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfid_as_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    291\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    292\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    294\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m use_arrow:\n\u001b[32m    295\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpyarrow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpa\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\anujx\\Documents\\GitHub\\venv\\Lib\\site-packages\\pyogrio\\raw.py:198\u001b[39m, in \u001b[36mread\u001b[39m\u001b[34m(path_or_buffer, layer, encoding, columns, read_geometry, force_2d, skip_features, max_features, where, bbox, mask, fids, sql, sql_dialect, return_fids, datetime_as_string, **kwargs)\u001b[39m\n\u001b[32m     59\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Read OGR data source into numpy arrays.\u001b[39;00m\n\u001b[32m     60\u001b[39m \n\u001b[32m     61\u001b[39m \u001b[33;03mIMPORTANT: non-linear geometry types (e.g., MultiSurface) are converted\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    194\u001b[39m \n\u001b[32m    195\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    196\u001b[39m dataset_kwargs = _preprocess_options_key_value(kwargs) \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[32m--> \u001b[39m\u001b[32m198\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mogr_read\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_vsi_path_or_buffer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_buffer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m    \u001b[49m\u001b[43mread_geometry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mread_geometry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforce_2d\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    205\u001b[39m \u001b[43m    \u001b[49m\u001b[43mskip_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskip_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    206\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_features\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    207\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    208\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbbox\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbbox\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    209\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_mask_to_wkb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    210\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    211\u001b[39m \u001b[43m    \u001b[49m\u001b[43msql\u001b[49m\u001b[43m=\u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    212\u001b[39m \u001b[43m    \u001b[49m\u001b[43msql_dialect\u001b[49m\u001b[43m=\u001b[49m\u001b[43msql_dialect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    213\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_fids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_fids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    214\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataset_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataset_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    215\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdatetime_as_string\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdatetime_as_string\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    216\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpyogrio/_io.pyx:1313\u001b[39m, in \u001b[36mpyogrio._io.ogr_read\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpyogrio/_io.pyx:232\u001b[39m, in \u001b[36mpyogrio._io.ogr_open\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mDataSourceError\u001b[39m: California_County_Boundary_view_layer_for_public_use_-4560719754002809188.geojson: No such file or directory"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, box\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "# Removed geopy imports - now using GeoJSON boundary for California filtering\n",
    "\n",
    "# --- 1. Paths & data sources ---\n",
    "WFIGS_CSV = r\"C:\\Users\\anujx\\Downloads\\WFIGS_Incident_Locations_-835549102613066266 (2).csv\"\n",
    "\n",
    "CALFIRE_GEOJSON_URLS = [\n",
    "    \"https://data.ca.gov/dataset/california-fire-perimeters-all/resource/dd5e4337-8679-4d64-bd90-b9df85ee6b58/download\", \n",
    "    \"https://services.arcgis.com/jIL9msH9OI208GCb/ArcGIS/rest/services/California_Fire_Perimeters_1878_2019/FeatureServer/1/query?where=1%3D1&outFields=*&f=geojson\",\n",
    "    \"https://gis.data.cnra.ca.gov/arcgis/rest/services/CALFIRE-Forestry/california-fire-perimeters-all/FeatureServer/0/query?where=1%3D1&outFields=*&f=geojson\"\n",
    "]\n",
    "\n",
    "def load_calfire_geojson_try(urls=CALFIRE_GEOJSON_URLS):\n",
    "    \"\"\"Try multiple sources until CAL FIRE GeoJSON loads.\"\"\"\n",
    "    for url in urls:\n",
    "        try:\n",
    "            print(\"Trying:\", url)\n",
    "            r = requests.get(url, timeout=60)\n",
    "            r.raise_for_status()\n",
    "            ct = r.headers.get(\"Content-Type\", \"\")\n",
    "            if \"json\" in ct or \"geojson\" in ct or r.text.strip().startswith(\"{\"):\n",
    "                data = r.json()\n",
    "                gdf = gpd.GeoDataFrame.from_features(data[\"features\"], crs=\"EPSG:4326\")\n",
    "                print(\"Loaded GeoJSON from:\", url)\n",
    "                return gdf\n",
    "            else:\n",
    "                print(\"Response not GeoJSON ({}): trying geopandas read_file fallback\".format(ct))\n",
    "                try:\n",
    "                    gdf = gpd.read_file(url)\n",
    "                    return gdf\n",
    "                except Exception as e:\n",
    "                    print(\"geopandas read_file failed for\", url, \"error:\", e)\n",
    "        except Exception as e:\n",
    "            print(\"Failed to load from\", url, \":\", e)\n",
    "    raise RuntimeError(\"Could not automatically download CAL FIRE perimeters.\")\n",
    "\n",
    "def is_in_california_geojson(latitude, longitude, california_gdf=None):\n",
    "    \"\"\"\n",
    "    Checks if a given latitude and longitude pair is within California using GeoJSON boundary data.\n",
    "    Much faster and more accurate than geopy reverse geocoding.\n",
    "    \"\"\"\n",
    "    if california_gdf is None:\n",
    "        # Load California boundary GeoJSON if not provided\n",
    "        california_gdf = gpd.read_file(\"California_County_Boundary_view_layer_for_public_use_-4560719754002809188.geojson\")\n",
    "        # Dissolve all counties into a single California boundary\n",
    "        california_gdf = california_gdf.dissolve()\n",
    "    \n",
    "    # Create a point from the coordinates (lat/lon)\n",
    "    point = Point(longitude, latitude)\n",
    "    \n",
    "    # Create a temporary GeoDataFrame with the point in lat/lon\n",
    "    point_gdf = gpd.GeoDataFrame([1], geometry=[point], crs=\"EPSG:4326\")\n",
    "    \n",
    "    # Convert the point to the same CRS as the California boundary\n",
    "    point_gdf = point_gdf.to_crs(california_gdf.crs)\n",
    "    \n",
    "    # Check if the point is within California\n",
    "    return california_gdf.geometry.iloc[0].contains(point_gdf.geometry.iloc[0])\n",
    "\n",
    "# --- 2. Load WFIGS incidents CSV ---\n",
    "print(\"Loading WFIGS incidents CSV...\")\n",
    "wf_df = pd.read_csv(WFIGS_CSV, low_memory=False)\n",
    "print(\"Columns in WFIGS CSV:\", wf_df.columns.tolist())\n",
    "\n",
    "# Detect coordinate columns - check both lat/lon and x/y columns\n",
    "lat_col, lon_col = None, None\n",
    "\n",
    "# First try to find lat/lon columns\n",
    "for c in [\"Latitude\", \"LAT\", \"lat\", \"InitialLatitude\"]:\n",
    "    if c in wf_df.columns:\n",
    "        lat_col = c\n",
    "        break\n",
    "for c in [\"Longitude\", \"LON\", \"lon\", \"InitialLongitude\"]:\n",
    "    if c in wf_df.columns:\n",
    "        lon_col = c\n",
    "        break\n",
    "\n",
    "# If lat/lon not found, try x/y columns (might be in projected coordinates)\n",
    "if not lat_col or not lon_col:\n",
    "    print(\"Lat/lon columns not found, checking x/y columns...\")\n",
    "    for c in [\"Y\", \"POINT_Y\", \"y\"]:\n",
    "        if c in wf_df.columns:\n",
    "            lat_col = c\n",
    "            break\n",
    "    for c in [\"X\", \"POINT_X\", \"x\"]:\n",
    "        if c in wf_df.columns:\n",
    "            lon_col = c\n",
    "            break\n",
    "\n",
    "if not lat_col or not lon_col:\n",
    "    raise RuntimeError(\"No latitude/longitude columns found.\")\n",
    "\n",
    "# Drop missing coords and convert to GeoDataFrame\n",
    "# Drop missing coords\n",
    "print(f\"Original WFIGS points: {len(wf_df)}\")\n",
    "wf_df = wf_df.dropna(subset=[lat_col, lon_col]).copy()\n",
    "print(f\"WFIGS points after dropping missing coordinates: {len(wf_df)}\")\n",
    "\n",
    "# Check coordinate ranges\n",
    "print(f\"Coordinate range - {lat_col}: {wf_df[lat_col].min()} to {wf_df[lat_col].max()}\")\n",
    "print(f\"Coordinate range - {lon_col}: {wf_df[lon_col].min()} to {wf_df[lon_col].max()}\")\n",
    "\n",
    "# Check if coordinates are in lat/lon format or projected coordinates\n",
    "is_latlon = (wf_df[lat_col].min() >= -90 and wf_df[lat_col].max() <= 90 and \n",
    "             wf_df[lon_col].min() >= -180 and wf_df[lon_col].max() <= 180)\n",
    "\n",
    "# Also check if they might be scaled lat/lon (e.g., degrees * 1000)\n",
    "is_scaled_latlon = (wf_df[lat_col].min() >= -90000 and wf_df[lat_col].max() <= 90000 and \n",
    "                    wf_df[lon_col].min() >= -180000 and wf_df[lon_col].max() <= 180000)\n",
    "\n",
    "if is_scaled_latlon:\n",
    "    print(\"Coordinates appear to be scaled lat/lon, trying different scales...\")\n",
    "    \n",
    "    # Try different scaling factors\n",
    "    scales = [1000, 10000, 100000, 1000000]\n",
    "    best_scale = None\n",
    "    \n",
    "    for scale in scales:\n",
    "        test_lats = wf_df[lat_col].head(100) / scale\n",
    "        test_lons = wf_df[lon_col].head(100) / scale\n",
    "        \n",
    "        lat_range = (test_lats.min(), test_lats.max())\n",
    "        lon_range = (test_lons.min(), test_lons.max())\n",
    "        \n",
    "        print(f\"  Scale {scale}: lat {lat_range[0]:.3f} to {lat_range[1]:.3f}, lon {lon_range[0]:.3f} to {lon_range[1]:.3f}\")\n",
    "        \n",
    "        # Check if this looks like reasonable US coordinates\n",
    "        if (lat_range[0] >= 25 and lat_range[1] <= 50 and \n",
    "            lon_range[0] >= -125 and lon_range[1] <= -65):\n",
    "            print(f\"  [OK] Scale {scale} looks like reasonable US coordinates!\")\n",
    "            best_scale = scale\n",
    "            break\n",
    "    \n",
    "    if best_scale is None:\n",
    "        print(\"  [X] No scale factor produced reasonable US coordinates\")\n",
    "        # Use original coordinates as-is\n",
    "        wf_df[\"lat_converted\"] = wf_df[lat_col]\n",
    "        wf_df[\"lon_converted\"] = wf_df[lon_col]\n",
    "    else:\n",
    "        print(f\"Using scale factor: {best_scale}\")\n",
    "        wf_df[\"lat_converted\"] = wf_df[lat_col] / best_scale\n",
    "        wf_df[\"lon_converted\"] = wf_df[lon_col] / best_scale\n",
    "    \n",
    "    print(f\"Converted coordinate range - lat: {wf_df['lat_converted'].min():.6f} to {wf_df['lat_converted'].max():.6f}\")\n",
    "    print(f\"Converted coordinate range - lon: {wf_df['lon_converted'].min():.6f} to {wf_df['lon_converted'].max():.6f}\")\n",
    "    \n",
    "    # Use converted coordinates for filtering\n",
    "    lat_col = \"lat_converted\"\n",
    "    lon_col = \"lon_converted\"\n",
    "elif not is_latlon:\n",
    "    print(\"Coordinates appear to be in projected coordinate system, trying different projections...\")\n",
    "    \n",
    "    # Try different common coordinate systems\n",
    "    possible_crs = [\n",
    "        \"EPSG:3857\",  # Web Mercator\n",
    "        \"EPSG:3310\",  # California Albers\n",
    "        \"EPSG:4269\",  # NAD83 (might be lat/lon but with different datum)\n",
    "        \"EPSG:4326\",  # WGS84 (in case the check was wrong)\n",
    "    ]\n",
    "    \n",
    "    best_conversion = None\n",
    "    best_crs = None\n",
    "    \n",
    "    for crs in possible_crs:\n",
    "        try:\n",
    "            print(f\"Trying CRS: {crs}\")\n",
    "            temp_gdf = gpd.GeoDataFrame(\n",
    "                wf_df.head(100),  # Test with first 100 points\n",
    "                geometry=[Point(xy) for xy in zip(wf_df[lon_col].head(100), wf_df[lat_col].head(100))],\n",
    "                crs=crs\n",
    "            )\n",
    "            \n",
    "            # Convert to lat/lon (WGS84)\n",
    "            temp_gdf = temp_gdf.to_crs(\"EPSG:4326\")\n",
    "            \n",
    "            # Check if conversion makes sense\n",
    "            converted_lats = [geom.y for geom in temp_gdf.geometry]\n",
    "            converted_lons = [geom.x for geom in temp_gdf.geometry]\n",
    "            \n",
    "            lat_range = (min(converted_lats), max(converted_lats))\n",
    "            lon_range = (min(converted_lons), max(converted_lons))\n",
    "            \n",
    "            print(f\"  Lat range: {lat_range[0]:.6f} to {lat_range[1]:.6f}\")\n",
    "            print(f\"  Lon range: {lon_range[0]:.6f} to {lon_range[1]:.6f}\")\n",
    "            \n",
    "            # Check if this looks like reasonable US coordinates\n",
    "            if (lat_range[0] >= 25 and lat_range[1] <= 50 and \n",
    "                lon_range[0] >= -125 and lon_range[1] <= -65):\n",
    "                print(f\"  [OK] This looks like reasonable US coordinates!\")\n",
    "                best_conversion = (converted_lats, converted_lons)\n",
    "                best_crs = crs\n",
    "                break\n",
    "            else:\n",
    "                print(f\"  [X] Coordinates don't look like US lat/lon\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"  [X] Failed with {crs}: {e}\")\n",
    "    \n",
    "    if best_conversion is None:\n",
    "        print(\"Could not determine correct coordinate system. Using original coordinates as-is.\")\n",
    "        print(\"Note: This may result in no points being identified as within California.\")\n",
    "    else:\n",
    "        print(f\"Using CRS: {best_crs}\")\n",
    "        # Apply conversion to all data\n",
    "        temp_gdf = gpd.GeoDataFrame(\n",
    "            wf_df,\n",
    "            geometry=[Point(xy) for xy in zip(wf_df[lon_col], wf_df[lat_col])],\n",
    "            crs=best_crs\n",
    "        )\n",
    "        temp_gdf = temp_gdf.to_crs(\"EPSG:4326\")\n",
    "        \n",
    "        wf_df[\"lat_converted\"] = [geom.y for geom in temp_gdf.geometry]\n",
    "        wf_df[\"lon_converted\"] = [geom.x for geom in temp_gdf.geometry]\n",
    "        \n",
    "        print(f\"Converted coordinate range - lat: {wf_df['lat_converted'].min():.6f} to {wf_df['lat_converted'].max():.6f}\")\n",
    "        print(f\"Converted coordinate range - lon: {wf_df['lon_converted'].min():.6f} to {wf_df['lon_converted'].max():.6f}\")\n",
    "        \n",
    "        # Use converted coordinates for filtering\n",
    "        lat_col = \"lat_converted\"\n",
    "        lon_col = \"lon_converted\"\n",
    "else:\n",
    "    print(\"Coordinates are already in lat/lon format\")\n",
    "\n",
    "# Pre-filter using California bounding box for performance\n",
    "print(\"Pre-filtering using California bounding box...\")\n",
    "# California bounding box coordinates (Northern, Western, Eastern, Southern)\n",
    "CA_NORTH = 42.00\n",
    "CA_WEST = -124.42\n",
    "CA_EAST = -114.12\n",
    "CA_SOUTH = 32.43\n",
    "\n",
    "print(f\"California bounding box: {CA_SOUTH}Â°N to {CA_NORTH}Â°N, {CA_WEST}Â°W to {CA_EAST}Â°W\")\n",
    "\n",
    "# Apply bounding box filter first (much faster than GeoJSON)\n",
    "bbox_mask = (\n",
    "    (wf_df[lat_col] >= CA_SOUTH) & (wf_df[lat_col] <= CA_NORTH) &\n",
    "    (wf_df[lon_col] >= CA_WEST) & (wf_df[lon_col] <= CA_EAST)\n",
    ")\n",
    "\n",
    "print(f\"Points within California bounding box: {bbox_mask.sum()} out of {len(bbox_mask)}\")\n",
    "wf_df_bbox = wf_df[bbox_mask].copy()\n",
    "\n",
    "if len(wf_df_bbox) == 0:\n",
    "    print(\"No points within California bounding box!\")\n",
    "    wf_df = wf_df_bbox\n",
    "else:\n",
    "    # Now apply precise GeoJSON boundary filter to the pre-filtered points\n",
    "    print(\"Loading California boundary for precise filtering...\")\n",
    "    california_gdf = gpd.read_file(\"California_County_Boundary_view_layer_for_public_use_-4560719754002809188.geojson\")\n",
    "    california_gdf = california_gdf.dissolve()  # Combine all counties into single boundary\n",
    "\n",
    "    print(\"Applying precise California boundary filter...\")\n",
    "    # Test a few coordinates first\n",
    "    test_coords = [(lat, lon) for lat, lon in zip(wf_df_bbox[lat_col].head(5), wf_df_bbox[lon_col].head(5))]\n",
    "    print(\"Testing first 5 coordinates:\")\n",
    "    for i, (lat, lon) in enumerate(test_coords):\n",
    "        result = is_in_california_geojson(lat, lon, california_gdf)\n",
    "        print(f\"  {i+1}. ({lat}, {lon}) -> {'IN' if result else 'OUT'} California\")\n",
    "\n",
    "    # Apply GeoJSON filter to the bounding box filtered data\n",
    "    precise_mask = [is_in_california_geojson(lat, lon, california_gdf) \n",
    "                   for lat, lon in zip(wf_df_bbox[lat_col], wf_df_bbox[lon_col])]\n",
    "    print(f\"Precise California filter results: {sum(precise_mask)} out of {len(precise_mask)} points are in California\")\n",
    "    \n",
    "    wf_df = wf_df_bbox[precise_mask].copy()\n",
    "    print(f\"WFIGS points after precise California filter: {len(wf_df)}\")\n",
    "\n",
    "# Convert to GeoDataFrame (keep this)\n",
    "wf_gdf = gpd.GeoDataFrame(\n",
    "    wf_df,\n",
    "    geometry=[Point(xy) for xy in zip(wf_df[lon_col], wf_df[lat_col])],\n",
    "    crs=\"EPSG:4326\"\n",
    ")\n",
    "\n",
    "\n",
    "# Remove invalid geometries\n",
    "wf_gdf = wf_gdf[wf_gdf.geometry.notnull() & ~wf_gdf.geometry.is_empty]\n",
    "if wf_gdf.empty:\n",
    "    raise RuntimeError(\"No valid WFIGS points after cleaning.\")\n",
    "\n",
    "# Reproject to California Albers (meters)\n",
    "wf_gdf = wf_gdf.to_crs(\"EPSG:3310\")\n",
    "print(\"Loaded WFIGS points:\", len(wf_gdf))\n",
    "print(\"Reprojected WFIGS CRS:\", wf_gdf.crs)\n",
    "\n",
    "\n",
    "# --- 3. Load CAL FIRE perimeters ---\n",
    "print(\"Downloading/reading CAL FIRE perimeters (FRAP)...\")\n",
    "calfire_url = CALFIRE_GEOJSON_URLS[1]  # you can cycle URLs if needed\n",
    "calfire_gdf = gpd.read_file(calfire_url)\n",
    "\n",
    "# Clean invalid geometries\n",
    "calfire_gdf = calfire_gdf[~calfire_gdf.geometry.is_empty]\n",
    "calfire_gdf = calfire_gdf[calfire_gdf.geometry.notnull()]\n",
    "calfire_gdf[\"geometry\"] = calfire_gdf[\"geometry\"].buffer(0)\n",
    "calfire_gdf = calfire_gdf[calfire_gdf.is_valid]\n",
    "\n",
    "# Reproject to California Albers\n",
    "calfire_gdf = calfire_gdf.to_crs(\"EPSG:3310\")\n",
    "print(\"CAL FIRE perimeters loaded. Features:\", len(calfire_gdf))\n",
    "print(\"CALFIRE bounds:\", calfire_gdf.total_bounds)\n",
    "\n",
    "# --- 4. Generate grid for modeling ---\n",
    "# Approximate California bounds in EPSG:3310 (meters)\n",
    "cell_size = 1000  # 1 km grid cells\n",
    "ca_minx, ca_miny = -2500000, -2500000\n",
    "ca_maxx, ca_maxy = 1100000, 1300000\n",
    "\n",
    "# Clip WFIGS points to California bounds\n",
    "wf_gdf = wf_gdf.cx[ca_minx:ca_maxx, ca_miny:ca_maxy]\n",
    "if wf_gdf.empty:\n",
    "    raise RuntimeError(\"No WFIGS points within California bounds.\")\n",
    "\n",
    "# Compute grid bounds safely\n",
    "minx, miny, maxx, maxy = wf_gdf.total_bounds\n",
    "nx = int(np.ceil((maxx - minx) / cell_size))\n",
    "ny = int(np.ceil((maxy - miny) / cell_size))\n",
    "\n",
    "print(f\"Grid size: {nx} Ã— {ny}\")\n",
    "\n",
    "grid_polys, grid_centroids = [], []\n",
    "for i in range(nx):\n",
    "    for j in range(ny):\n",
    "        x0, y0 = minx + i*cell_size, miny + j*cell_size\n",
    "        x1, y1 = x0 + cell_size, y0 + cell_size\n",
    "        grid_polys.append(box(x0, y0, x1, y1))\n",
    "        grid_centroids.append(((x0+x1)/2, (y0+y1)/2))\n",
    "\n",
    "grid_gdf = gpd.GeoDataFrame(geometry=grid_polys, crs=\"EPSG:3310\")\n",
    "grid_gdf[\"centroid\"] = [Point(c) for c in grid_centroids]\n",
    "\n",
    "# Clip grid to area around WFIGS points (study area)\n",
    "study_buffer = 5000\n",
    "wf_bounds = wf_gdf.total_bounds  # Get bounds from the filtered WFIGS data\n",
    "study_box = box(wf_bounds[0]-study_buffer, wf_bounds[1]-study_buffer,\n",
    "                wf_bounds[2]+study_buffer, wf_bounds[3]+study_buffer)\n",
    "grid_gdf = grid_gdf[grid_gdf.intersects(study_box)].reset_index(drop=True)\n",
    "print(\"Grid cells after clipping:\", len(grid_gdf))\n",
    "\n",
    "# --- 5. Compute features ---\n",
    "calfire_gdf[\"perim_area\"] = calfire_gdf.geometry.area\n",
    "calfire_sindex = calfire_gdf.sindex\n",
    "\n",
    "def compute_burned_area_for_cell(cell_geom):\n",
    "    possible_idx = list(calfire_sindex.intersection(cell_geom.bounds))\n",
    "    return sum(\n",
    "        calfire_gdf.geometry.iloc[i].intersection(cell_geom).area\n",
    "        for i in possible_idx\n",
    "        if calfire_gdf.geometry.iloc[i].intersects(cell_geom)\n",
    "    )\n",
    "\n",
    "grid_gdf[\"burned_area_m2\"] = [\n",
    "    compute_burned_area_for_cell(g) for g in tqdm(grid_gdf.geometry, desc=\"computing burned area\")\n",
    "]\n",
    "grid_gdf[\"burned_area_km2\"] = grid_gdf[\"burned_area_m2\"] / 1e6\n",
    "\n",
    "def count_perimeters_in_cell(cell_geom):\n",
    "    possible_idx = list(calfire_sindex.intersection(cell_geom.bounds))\n",
    "    return sum(\n",
    "        calfire_gdf.geometry.iloc[i].intersects(cell_geom)\n",
    "        for i in possible_idx\n",
    "    )\n",
    "\n",
    "grid_gdf[\"burn_count\"] = [\n",
    "    count_perimeters_in_cell(g) for g in tqdm(grid_gdf.geometry, desc=\"counting perimeters\")\n",
    "]\n",
    "\n",
    "# Distance to nearest perimeter\n",
    "centroids = gpd.GeoSeries([p for p in grid_gdf.centroid], crs=\"EPSG:3310\")\n",
    "nearest_distances = []\n",
    "for c in tqdm(centroids, desc=\"computing distance\"):\n",
    "    try:\n",
    "        possible_idx = list(calfire_sindex.nearest(c.bounds))\n",
    "    except TypeError:\n",
    "        possible_idx = list(calfire_sindex.intersection(c.bounds))\n",
    "    dmin = np.min([c.distance(calfire_gdf.geometry.iloc[i]) for i in possible_idx]) if possible_idx else np.inf\n",
    "    nearest_distances.append(dmin if np.isfinite(dmin) else 0)\n",
    "\n",
    "grid_gdf[\"dist_to_perimeter_m\"] = nearest_distances"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
